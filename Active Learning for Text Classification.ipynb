{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Active Learning for Text Classification Algorithm from AWS Marketplace \n",
    "\n",
    "Active Learning for Text Classification trains a text classification model using a small corpus of training data and provides the most appropriate samples from a huge corpus of unlabeled data to be annotated in order to improve the model accuracy significantly. Using Active Learning this algorithm helps in identifying the most effective data sample to be tagged first thus reducing the time and effort to build a usable Machine learning model.\n",
    "\n",
    "Active Learning for Text Classification can be used for prioritizing the data labeling task and thereby drastically reduce the data tagging effort required to build a working Machine Learning model.\n",
    "\n",
    "This solution can be used to iteratively sample the right data points & train the Machine Learning model to  build a  supervised machine learning algorithm. It helps in identifying which samples to label first based on the rules learned by Machine Learning model. It uses Active Learning methodologies to select the right sample data points from unlabeled data to build a better performing machine learning model much faster.\n",
    "\n",
    "This sample notebook shows you how to deploy Active Learning for Text Classification Algorithm using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to Active Learning for Text Classification.\n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the Algorithm](#1.-Subscribe-to-the-Algorithm)\n",
    "2. [Prepare dataset](#2.-Prepare-dataset)\n",
    "    1. [Dataset format expected by the algorithm](#A.-Dataset-format-expected-by-the-algorithm)\n",
    "    2. [Configure and visualize train,validation and test dataset](#B.-Configure-and-visualize-train,-validation-and-test-dataset)\n",
    "    3. [Upload datasets to Amazon S3](#C.-Upload-datasets-to-Amazon-S3)\n",
    "3. [Train a machine learning model](#3.-Train-a-machine-learning-model)\n",
    "    1. [Set up environment](#A.-Set-up-environment)\n",
    "    2. [Train a model](#B.-Train-a-model)\n",
    "4. [Deploy model and verify results](#4.-Deploy-model-and-verify-results)\n",
    "    1. [Deplay trained model](#A.-Deploy-trained-model)\n",
    "    2. [Create input payload](#B.-Create-input-payload)\n",
    "    3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "    4. [Visualize output](#D.-Visualize-output)\n",
    "    5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "5. [Perform Batch inference](#5.-Perform-Batch-inference)\n",
    "    1. [Inspect the Batch Transform Output in S3](#A.-Inspect-the-Batch-Transform-Output-in-S3)\n",
    "6. [Clean-up](#6.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the Algorithm:\n",
    "1. Open the algorithm listing page **Active Learning for Text Classification**\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the algorithm ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_arn ='arn:aws:sagemaker:us-east-2:786796469737:algorithm/active-learning-text-classification-v04'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json \n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.algorithm import AlgorithmEstimator\n",
    "from sagemaker import ModelPackage\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "from IPython.display import Image\n",
    "from PIL import Image as ImageEdit\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deployed solution has these **2 steps**: Training the algorithm and Testing\n",
    "\n",
    "<li>: The system trains on user provided text dataset.\n",
    "<li>: The train dataset must contain 2 files - \"train.csv\" and \"validation.csv\" with 'utf-8' encoding.\n",
    "<li>: The machine learning model is trained in the training step and once the model is generated, it can be used to sample data points from unlabelled data using active learning technique.\n",
    "<li>: The testing API takes a csv file \"unlabelled.csv\" from which the data points are sampled for human annotation.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train.csv**\n",
    "<li>: train.csv must contain 3 columns - <b>ID</b>, <b>Text</b> and <b>Category</b>. The <b>ID</b> is a unique identification number associated with the text, <b>Text</b> will have textual data that needs to be categorized and <b>Category</b> will be class with the associated text.\n",
    "<li>: It is recommended to start with small amount of annotated data in train.csv and increase the training data size iteratively by sampling data points from unlabelled data.\n",
    "<li>: After each iteration of model building and text sampling from unlabelled data, the model returned sampled data should be annotated and added to the train.csv. The same data points should be removed from unlabelled dataset.<br>\n",
    "\n",
    "**validation.csv**\n",
    "<li>: The format of validation.csv is similar to train.csv and must contain 3 columns - <b>ID</b>, <b>Text</b> and <b>Category</b>.\n",
    "<li>: The validation.csv is used to check the accuracy of model.\n",
    "<li>: The contents of the validation.csv should not be altered as it will demonstrate the change in accuracy after each iteration of sampling, annotation and training.<br>\n",
    "    \n",
    "**unlablled.csv**\n",
    "<li>: The unlabelled.csv must contain 2 columns - <b>ID</b> and <b>Text</b>.\n",
    "<li>: The unlablled.csv is the huge corpus of unlabelled data from which data points will be sampled for annotation. The sampling will be done using active learning technique instead of random sampling.\n",
    "<li>: The active learning sampling helps in attaining better machine learning model accuracy in less as the amount of data points labelled is reduced drastically.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Configure and visualize train, validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset='data/training/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset='data/training/validation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2035</td>\n",
       "      <td>errors  doomed first dome sale the initial att...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>lib dems  to target stamp duty  the liberal de...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1374</td>\n",
       "      <td>uk economy facing  major risks  the uk manufac...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>360</td>\n",
       "      <td>baa support ahead of court battle uk airport o...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1598</td>\n",
       "      <td>survey confirms property slowdown government f...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    ID                                               Text  \\\n",
       "0           0  2035  errors  doomed first dome sale the initial att...   \n",
       "1           1   440  lib dems  to target stamp duty  the liberal de...   \n",
       "2           2  1374  uk economy facing  major risks  the uk manufac...   \n",
       "3           3   360  baa support ahead of court battle uk airport o...   \n",
       "4           4  1598  survey confirms property slowdown government f...   \n",
       "\n",
       "   Category  \n",
       "0  politics  \n",
       "1  politics  \n",
       "2  business  \n",
       "3  politics  \n",
       "4  business  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_df = pd.read_csv(training_dataset)\n",
    "train_input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>williams stays on despite dispute matt william...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1424</td>\n",
       "      <td>robben and cole earn chelsea win cheslea salva...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2186</td>\n",
       "      <td>us bank  loses  customer details the bank of a...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1109</td>\n",
       "      <td>cairn shares up on new oil find shares in cair...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1579</td>\n",
       "      <td>golden rule boost for chancellor chancellor go...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    ID                                               Text  \\\n",
       "0           0   900  williams stays on despite dispute matt william...   \n",
       "1           1  1424  robben and cole earn chelsea win cheslea salva...   \n",
       "2           2  2186  us bank  loses  customer details the bank of a...   \n",
       "3           3  1109  cairn shares up on new oil find shares in cair...   \n",
       "4           4  1579  golden rule boost for chancellor chancellor go...   \n",
       "\n",
       "   Category  \n",
       "0     sport  \n",
       "1     sport  \n",
       "2  business  \n",
       "3  business  \n",
       "4  business  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_input_df = pd.read_csv(validation_dataset)\n",
    "validation_input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset='data/transform/unlabelled.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1149</td>\n",
       "      <td>council tax rise  reasonable  welsh councils s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1524</td>\n",
       "      <td>fa charges liverpool and millwall liverpool an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2198</td>\n",
       "      <td>campbell returns to election team ex-downing s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>346</td>\n",
       "      <td>clijsters could play aussie open kim clijsters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1370</td>\n",
       "      <td>anelka  eyes man city departure  striker nicol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    ID                                               Text\n",
       "0           0  1149  council tax rise  reasonable  welsh councils s...\n",
       "1           1  1524  fa charges liverpool and millwall liverpool an...\n",
       "2           2  2198  campbell returns to election team ex-downing s...\n",
       "3           3   346  clijsters could play aussie open kim clijsters...\n",
       "4           4  1370  anelka  eyes man city departure  striker nicol..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_df = pd.read_csv(test_dataset)\n",
    "test_input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()\n",
    "bucket=sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training input location\n",
    "common_prefix = \"active-learning\"\n",
    "training_input_prefix = common_prefix + \"/training-input-data\"\n",
    "TRAINING_WORKDIR = \"data/training\"\n",
    "training_input = sagemaker_session.upload_data(TRAINING_WORKDIR, key_prefix=training_input_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-786796469737/active-learning/batch-inference-input-data/unlabelled.csv\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM_WORKDIR = \"data/transform\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\"\n",
    "transform_input = sagemaker_session.upload_data(TRANSFORM_WORKDIR, key_prefix=batch_inference_input_prefix) + \"/unlabelled.csv\"\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train a machine learning model\n",
    "\n",
    "Now that dataset is available in an accessible Amazon S3 bucket, we are ready to train a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = AlgorithmEstimator(\n",
    "    algorithm_arn=algorithm_arn,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c4.xlarge',\n",
    "    base_job_name='active-learning-marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now run the training job using algorithm arn arn:aws:sagemaker:us-east-2:786796469737:algorithm/active-learning-text-classification-v04 in region us-east-2\n",
      "2021-06-24 03:17:05 Starting - Starting the training job...\n",
      "2021-06-24 03:17:07 Starting - Launching requested ML instancesProfilerReport-1624504625: InProgress\n",
      "...\n",
      "2021-06-24 03:18:01 Starting - Preparing the instances for training.........\n",
      "2021-06-24 03:19:29 Downloading - Downloading input data\n",
      "2021-06-24 03:19:29 Training - Downloading the training image.....\u001b[34mTraining Starts\u001b[0m\n",
      "\n",
      "2021-06-24 03:20:35 Uploading - Uploading generated training model\n",
      "2021-06-24 03:20:35 Completed - Training job completed\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\u001b[0m\n",
      "\u001b[34m[03:20:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\u001b[34mAccuracy : 0.84\u001b[0m\n",
      "\u001b[34m['text_classification_model.pkl', 'vectorizer.pk']\u001b[0m\n",
      "\u001b[34m/opt/ml/model\u001b[0m\n",
      "\u001b[34mAccuracy: train=84.000\u001b[0m\n",
      "Training seconds: 81\n",
      "Billable seconds: 81\n"
     ]
    }
   ],
   "source": [
    "print (\"Now run the training job using algorithm arn %s in region %s\" % (algorithm_arn, sagemaker_session.boto_region_name))\n",
    "algo.fit({'training': training_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Deploy model and verify results\n",
    "Now you can deploy the model for performing real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='active-learning'\n",
    "\n",
    "content_type='text/csv'\n",
    "\n",
    "real_time_inference_instance_type='ml.c4.xlarge'\n",
    "batch_transform_inference_instance_type='ml.c4.large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Deploy trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "------------!"
     ]
    }
   ],
   "source": [
    "#Deploy the model\n",
    "predictor = algo.deploy(1, 'ml.c4.xlarge',endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint is created, you can perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/transform/unlabelled.csv'\n",
    "output_file_name = 'output.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"ContentType\": \"text/csv; charset=utf-8\",\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name 'active-learning' \\\n",
    "    --body fileb://$file_name \\\n",
    "    --content-type 'text/csv' \\\n",
    "    --region us-east-2 \\\n",
    "    output_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>:  The output will be a csv file with sampled data points from unlablled data. The output csv file will contain ID and the associated text sampled for human annotation.\n",
    "<li>: These sampled datapoints should be annotated, added to train.csv and removed from unlablled.csv before training the machine learning model again.\n",
    "<li>: Now, the machine learning model will be trained on a bigger and better data set capturing variability present in the data and provide updated accuracy number on the validation dataset.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1697</td>\n",
       "      <td>us airways staff agree to pay cut a union repr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>935</td>\n",
       "      <td>civil servants in strike ballot the uk s bigge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2108</td>\n",
       "      <td>game warnings  must be clearer  violent video ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>896</td>\n",
       "      <td>jp morgan admits us slavery links thousands of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1838</td>\n",
       "      <td>watchdog probes e-mail deletions the informati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>967</td>\n",
       "      <td>italy to get economic action plan italian prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1465</td>\n",
       "      <td>bmw cash to fuel mini production less than fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1605</td>\n",
       "      <td>kilroy launches  veritas  party ex-bbc chat sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1156</td>\n",
       "      <td>bid to cut court witness stress new targets to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1217</td>\n",
       "      <td>uefa approves fake grass uefa says it will all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    ID                                               Text\n",
       "0           0  1697  us airways staff agree to pay cut a union repr...\n",
       "1           1   935  civil servants in strike ballot the uk s bigge...\n",
       "2           2  2108  game warnings  must be clearer  violent video ...\n",
       "3           3   896  jp morgan admits us slavery links thousands of...\n",
       "4           4  1838  watchdog probes e-mail deletions the informati...\n",
       "5           5   967  italy to get economic action plan italian prim...\n",
       "6           6  1465  bmw cash to fuel mini production less than fou...\n",
       "7           7  1605  kilroy launches  veritas  party ex-bbc chat sh...\n",
       "8           8  1156  bid to cut court witness stress new targets to...\n",
       "9           9  1217  uefa approves fake grass uefa says it will all..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.read_csv(output_file_name)\n",
    "output.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Delete the endpoint\n",
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. you can terminate the same to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perform Batch inference\n",
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-786796469737/active-learning/batch-inference-input-data/unlabelled.csv\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM_WORKDIR = \"data/transform\"\n",
    "transform_input = sagemaker_session.upload_data(TRANSFORM_WORKDIR, key_prefix=batch_inference_input_prefix) + \"/unlabelled.csv\"\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      ".........................\u001b[34mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [12] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [12] [INFO] Listening at: unix:/tmp/gunicorn.sock (12)\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [12] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Jun/2021:03:52:38 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Jun/2021:03:52:38 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [24/Jun/2021:03:52:38 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [24/Jun/2021:03:52:38 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-06-24T03:52:38.148:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "\u001b[34mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[35mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [12] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [12] [INFO] Listening at: unix:/tmp/gunicorn.sock (12)\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [12] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[34m[2021-06-24 03:52:30 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[35m[2021-06-24 03:52:30 +0000] [12] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[35m[2021-06-24 03:52:30 +0000] [12] [INFO] Listening at: unix:/tmp/gunicorn.sock (12)\u001b[0m\n",
      "\u001b[35m[2021-06-24 03:52:30 +0000] [12] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-06-24 03:52:30 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[35m[2021-06-24 03:52:30 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[35m[2021-06-24 03:52:30 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[35m[2021-06-24 03:52:30 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Jun/2021:03:52:38 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Jun/2021:03:52:38 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [24/Jun/2021:03:52:38 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [24/Jun/2021:03:52:38 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-06-24T03:52:38.148:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Jun/2021:03:52:48 +0000] \"POST /invocations HTTP/1.1\" 200 79410 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [24/Jun/2021:03:52:48 +0000] \"POST /invocations HTTP/1.1\" 200 79410 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "Batch Transform output saved to s3://sagemaker-us-east-2-786796469737/active-learning-marketplace-2021-06-24-03-48-29-936\n"
     ]
    }
   ],
   "source": [
    "transformer = algo.transformer(1, 'ml.m4.xlarge')\n",
    "transformer.transform(transform_input, content_type='text/csv')\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-786796469737/active-learning-marketplace-2021-06-24-03-48-29-936'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output is available on following path\n",
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Inspect the Batch Transform Output in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "parsed_url = urlparse(transformer.output_path)\n",
    "bucket_name = parsed_url.netloc\n",
    "file_key = '{}/{}.out'.format(parsed_url.path[1:], \"unlabelled.csv\")\n",
    "\n",
    "s3_client = sagemaker_session.boto_session.client('s3')\n",
    "\n",
    "response = s3_client.get_object(Bucket = sagemaker_session.default_bucket(), Key = file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketFolder = transformer.output_path.rsplit('/')[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "s3_conn = boto3.client(\"s3\")\n",
    "bucket_name=bucket\n",
    "with open('output.csv', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket_name, bucketFolder+'/' + \"unlabelled.csv\" +'.out', f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>:  The output will be a csv file with sampled data points from unlablled data. The output csv file will contain ID and the associated text sampled for human annotation.\n",
    "<li>: These sampled datapoints should be annotated, added to train.csv and removed from unlablled.csv before training the machine learning model again.\n",
    "<li>: Now, the machine learning model will be trained on a bigger and better data set capturing variability present in the data and provide updated accuracy number on the validation dataset.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1697</td>\n",
       "      <td>us airways staff agree to pay cut a union repr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>935</td>\n",
       "      <td>civil servants in strike ballot the uk s bigge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2108</td>\n",
       "      <td>game warnings  must be clearer  violent video ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>896</td>\n",
       "      <td>jp morgan admits us slavery links thousands of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1838</td>\n",
       "      <td>watchdog probes e-mail deletions the informati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>967</td>\n",
       "      <td>italy to get economic action plan italian prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1465</td>\n",
       "      <td>bmw cash to fuel mini production less than fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1605</td>\n",
       "      <td>kilroy launches  veritas  party ex-bbc chat sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1156</td>\n",
       "      <td>bid to cut court witness stress new targets to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1217</td>\n",
       "      <td>uefa approves fake grass uefa says it will all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    ID                                               Text\n",
       "0           0  1697  us airways staff agree to pay cut a union repr...\n",
       "1           1   935  civil servants in strike ballot the uk s bigge...\n",
       "2           2  2108  game warnings  must be clearer  violent video ...\n",
       "3           3   896  jp morgan admits us slavery links thousands of...\n",
       "4           4  1838  watchdog probes e-mail deletions the informati...\n",
       "5           5   967  italy to get economic action plan italian prim...\n",
       "6           6  1465  bmw cash to fuel mini production less than fou...\n",
       "7           7  1605  kilroy launches  veritas  party ex-bbc chat sh...\n",
       "8           8  1156  bid to cut court witness stress new targets to...\n",
       "9           9  1217  uefa approves fake grass uefa says it will all..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)\n",
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
